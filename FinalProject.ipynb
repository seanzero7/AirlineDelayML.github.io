{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries, initialize the starting year and ending year. \n",
    "Select columns that you want to read in.\n",
    "Select the desired airlines via codes. This can be found on The  Bureau of Transportation's website \n",
    "Start the timer and initialize an empty list where the dataframes will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "start_year = 2013\n",
    "end_year = 2023\n",
    "\n",
    "selected_columns = ['Year', 'Month', 'DayofMonth', 'DayOfWeek', 'DOT_ID_Reporting_Airline',\n",
    "                     'OriginAirportID', 'OriginCityName',\n",
    "                    'DestAirportID','DestCityName', 'CRSDepTime', 'DepTime', 'DepDelayMinutes',\n",
    "                     'TaxiOut', 'TaxiIn', 'CRSArrTime', 'ArrTime', 'ArrDelayMinutes',\n",
    "                     'Cancelled', 'CancellationCode', 'Diverted', 'CRSElapsedTime',\n",
    "                     'ActualElapsedTime', 'AirTime', 'Distance', 'CarrierDelay', 'WeatherDelay',\n",
    "                     'NASDelay', 'SecurityDelay', 'LateAircraftDelay']\n",
    "\n",
    "Top10AirportCodes = [11298, 12892, 10397, 11292, 12266, 12264, 13204, 13930, 12478, 14747]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "data_frames = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A for loop then reads in the files from my computer and combines them into a single dataframe.\n",
    "    Note: the year 2023 only has 8 months of data.\n",
    "Prints an exception if a file was not downloaded properly. Only reads in the rows where the column \"OriginAirportID\" has a value in the Top10AirportCodes. Append dataframe to the list. Documents time and lets me know when the program is complete. Outputs to the file (called 10Airlines.csv) in the folder airline_data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(start_year, end_year + 1):\n",
    "    max_month = 12 if year != 2023 else 8\n",
    "    for month in range(1, max_month + 1):\n",
    "        file_path = f\"airline_data/{year}/On_Time_Reporting_Carrier_On_Time_Performance_1987_present_{year}_{month}/On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_{year}_{month}.csv\"\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, usecols=selected_columns)\n",
    "            df = df[df['OriginAirportID'].isin(Top10AirportCodes) & df['DestAirportID'].isin(Top10AirportCodes)]\n",
    "            data_frames.append(df)\n",
    "\n",
    "        except FileNotFoundError: \n",
    "            print(f\"File not found for {year}-{month}\")\n",
    "\n",
    "final_df = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time} seconds\")\n",
    "\n",
    "output_dir = 'airline_data'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "final_df.to_csv(os.path.join(output_dir, '10Airlines.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads in the DataFrame and Foreign Keys which map codes to strings. Cleans data and missing values \n",
    "I drop the cancellation rows as this would confuse the machine learning model for predicing delays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('airline_data/10Airlines.csv')\n",
    "\n",
    "#Cleaning CancellationCodes\n",
    "df[\"CancellationReason\"] = df[\"CancellationCode\"].replace({'A':\"Carrier\",'B':\"Weather\",'C':\"National Air System\",'D':\"Security\",np.nan:'No Delay'})\n",
    "df.drop(columns=['CancellationCode'],inplace=True)\n",
    "\n",
    "#Cleaning Airline name \n",
    "DOT_ID_Airline_df = pd.read_csv('airline_data/L_AIRLINE_ID.csv')\n",
    "ID_map_dict = dict(zip(DOT_ID_Airline_df['Code'], DOT_ID_Airline_df['Description'].str.split(':').str[0])) \n",
    "df['Airline'] = df['DOT_ID_Reporting_Airline'].map(ID_map_dict)\n",
    "df.drop(columns=['DOT_ID_Reporting_Airline'],inplace=True)\n",
    "#Fix this outlier\n",
    "df['Airline'] = df['Airline'].replace('ExpressJet Airlines LLC d/b/a aha!', 'ExpressJet Airlines')\n",
    "\n",
    "#Cleaning Delays (Some airlines did NaN on delays when they didn't exist. These are equivalent to a 0 time delay.)\n",
    "fill_columns = ['CarrierDelay','WeatherDelay','NASDelay','SecurityDelay','LateAircraftDelay']\n",
    "df[fill_columns] = df[fill_columns].fillna(0)\n",
    "\n",
    "#Cleaning DayOfWeek \n",
    "DayOfWeek_mapping = {1:'Mon',2:'Tues',3:'Wed',4:'Thurs',5:'Fri',6:'Sat',7:'Sun'}\n",
    "df['DayOfWeek'] = df['DayOfWeek'].map(DayOfWeek_mapping)\n",
    "\n",
    "#Cleaning OriginAirportID\n",
    "ForeignKey = pd.read_csv('airline_data/L_AIRPORT_ID.csv')\n",
    "ForeignKeyDict = dict(zip(ForeignKey['Code'], ForeignKey['Description']))\n",
    "df['OriginAirport'] = df['OriginAirportID'].map(ForeignKeyDict)\n",
    "df.drop(columns=['OriginAirportID'],inplace=True)\n",
    "\n",
    "#Cleaning Months\n",
    "ForeignKey = pd.read_csv('airline_data/L_MONTHS.csv')\n",
    "ForeignKeyDict = dict(zip(ForeignKey['Code'], ForeignKey['Description']))\n",
    "df['Month'] = df['Month'].map(ForeignKeyDict)\n",
    "\n",
    "#Cleaning DestAirportID\n",
    "ForeignKey = pd.read_csv('airline_data/L_AIRPORT_ID.csv')\n",
    "ForeignKeyDict = dict(zip(ForeignKey['Code'], ForeignKey['Description']))\n",
    "df['DestAirport'] = df['DestAirportID'].map(ForeignKeyDict)\n",
    "df.drop(columns=['DestAirportID'],inplace=True)\n",
    "\n",
    "#Dropping Canceled Rows for Regression Model\n",
    "df = df[df['Cancelled'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2% of rows have NaN values. I looked for a correlation between these rows and none existed. This should not affect our data. We will drop these rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A brief look at correlations via a correlation matrix for numeric columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = ['ArrDelayMinutes', 'DepDelayMinutes']\n",
    "\n",
    "numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "correlation_matrix = df[numeric_columns].corr()\n",
    "\n",
    "correlations_with_target = correlation_matrix[target_columns]\n",
    "\n",
    "for target_column in target_columns:\n",
    "    correlated_columns = correlations_with_target[target_column].sort_values(ascending=False)\n",
    "    print(f\"\\nColumns most correlated with '{target_column}':\")\n",
    "    print(correlated_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then look for a good threshhold for what is considered a delay. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Decile 1:\", df['ArrDelayMinutes'].quantile(0.10))\n",
    "print(\"Decile 2:\", df['ArrDelayMinutes'].quantile(0.20))\n",
    "print(\"Decile 3:\", df['ArrDelayMinutes'].quantile(0.30))\n",
    "print(\"Decile 4:\", df['ArrDelayMinutes'].quantile(0.40))\n",
    "print(\"Decile 5:\", df['ArrDelayMinutes'].quantile(0.50))\n",
    "print(\"Decile 6:\", df['ArrDelayMinutes'].quantile(0.60))\n",
    "print(\"Decile 7:\", df['ArrDelayMinutes'].quantile(0.70))\n",
    "print(\"Decile 8:\", df['ArrDelayMinutes'].quantile(0.80))\n",
    "print(\"Decile 9:\", df['ArrDelayMinutes'].quantile(0.90))\n",
    "print(\"Decile 10:\", df['ArrDelayMinutes'].quantile(1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 minute delay is a bit above the median so this will be our threshold for a delay. \n",
    "We then create a new Boolean column for whether the flight was delayed or not. \n",
    "Then we rewrite the DataFrame into a csv for convenience. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Delayed'] = df['ArrDelayMinutes'] >= 5\n",
    "df.to_csv('PreWeatherML.csv', index=False, mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we find some fun facts out of curiousity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Airline with the Most Delays:\n",
    "most_delayed_airline = df.groupby('Airline')['ArrDelayMinutes'].mean().idxmax()\n",
    "print(f\"The airline with the most delays is {most_delayed_airline}.\")\n",
    "\n",
    "#Month with the Most Delays:\n",
    "month_most_delays = df.groupby('Month')['ArrDelayMinutes'].mean().idxmax()\n",
    "print(f\"The month with the most delays is {month_most_delays}.\")\n",
    "\n",
    "#Year with the Most Delays:\n",
    "year_most_delays = df.groupby('Year')['ArrDelayMinutes'].mean().idxmax()\n",
    "print(f\"The year with the most delays is {year_most_delays}.\")\n",
    "\n",
    "#Airport with the Longest Average Taxi Out Time:\n",
    "airport_longest_taxi_out = df.groupby('OriginAirport')['TaxiOut'].mean().idxmax()\n",
    "print(f\"The airport with the longest average taxi out time is {airport_longest_taxi_out}.\")\n",
    "\n",
    "#Average Delay by City:\n",
    "avg_arrival_delay_by_city = df.groupby('DestCityName')['ArrDelayMinutes'].mean().idxmax()\n",
    "print(f\"The city with the highest average arrival delay is {avg_arrival_delay_by_city}.\")\n",
    "\n",
    "#Busiest Airport (Most Flights):\n",
    "busiest_airport = df['OriginAirport'].value_counts().idxmax()\n",
    "print(f\"The busiest airport (with the most flights) is {busiest_airport}.\")\n",
    "\n",
    "#Month with the Highest Average Airtime:\n",
    "month_highest_airtime = df.groupby('Month')['AirTime'].mean().idxmax()\n",
    "print(f\"The month with the highest average airtime is {month_highest_airtime}.\")\n",
    "\n",
    "#Most Common Delay Type:\n",
    "most_common_delay_type = df[['CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay']].idxmax(axis=1).mode().values[0]\n",
    "print(f\"The most common delay type is {most_common_delay_type}.\")\n",
    "\n",
    "#Day of the Week with the Fewest Delays:\n",
    "day_fewest_delays = df.groupby('DayOfWeek')['ArrDelayMinutes'].mean().idxmin()\n",
    "print(f\"The day of the week with the fewest delays is {day_fewest_delays}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now prepare for the machine learning step. Import in the necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weather gets read in here: Preprocessed into a MLRead file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLReady csv gets read in. Relevant features are defined as well as the variable that will be predicted. We are quantitatively predicting the delay time, so a random forest regression model will be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('MLReady.csv')\n",
    "\n",
    "selected_columns = ['Year', 'DayofMonth', 'Month', 'CRSDepTime', 'DepDelayMinutes',\n",
    "                    'CRSArrTime', 'Distance', 'OriginSnow_Last2', 'OriginPrcp_Last2', 'OriginSnow',\n",
    "                    'OriginPrcp', 'DestSnow_Last2', 'DestPrcp_Last2', 'DestSnow', 'DestPrcp',\n",
    "                    'OriginAirport', 'DestAirport', 'DayOfWeek', 'Airline', 'ArrDelayMinutes']\n",
    "\n",
    "#Excludes other columns\n",
    "df = df[selected_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define the categorical and numerical features of the model.\n",
    "We create a list to store the evaluation metrics of each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['OriginAirport', 'DestAirport', 'DayOfWeek', 'Airline']\n",
    "numerical_features = df.drop(columns=['ArrDelayMinutes']).columns.difference(categorical_features)\n",
    "\n",
    "mae_list = []\n",
    "r2_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform the categorical variables by One Hot Encoding\n",
    "We also define the scaler for the pipeline (Z-standardizing)\n",
    "We define the preprocessor to deal with the cateogrical features and create the model\n",
    "\n",
    "We want our model to train on year 2013 and test on 2014, then record its error, then train on 2014, and test on 2015 and so on. This will require a rolling regression model. The model then print its error for the current iteration, then after the for loop terminates, prints the average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2013, 2023):\n",
    "    train_data = df[df['Year'] == year]\n",
    "    test_data = df[df['Year'] == (year + 1)]\n",
    "\n",
    "    X_train = train_data.drop(columns=['ArrDelayMinutes'])\n",
    "    y_train = train_data['ArrDelayMinutes']\n",
    "\n",
    "    X_test = test_data.drop(columns=['ArrDelayMinutes'])\n",
    "    y_test = test_data['ArrDelayMinutes']\n",
    "\n",
    "    numerical_transformer = StandardScaler()\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "\n",
    "    model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                             ('regressor', RandomForestRegressor(n_estimators=10, random_state=42))])\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    mae_list.append(mae)\n",
    "    r2_list.append(r2)\n",
    "\n",
    "    print(f'Training on {year}, Testing on {year + 1} - Mean Absolute Error: {mae}, R-squared: {r2}')\n",
    "\n",
    "print(f'Average Mean Absolute Error: {sum(mae_list) / len(mae_list)}')\n",
    "print(f'Average R-squared: {sum(r2_list) / len(r2_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the model, \"n_estimators = 10\" can be increased for a more accurate depiction. However, due to the size of our data, n=10 will take 20+ minutes to load on an average computer so we figured this to be sufficient. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the results are pretty accurate. Now we will test this model on both Julia and my flight. Due to 2023 being an incomplete year, we will train on 2022. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be the input for our flight back home. We will take this input and turn it into a separate DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sean_flight_data = {\n",
    "    'Year': 2023,\n",
    "    'DayofMonth': 13,\n",
    "    'Month': 12,\n",
    "    'CRSDepTime': 1759,\n",
    "    'DepDelayMinutes': 0,  # Replace with the actual delay for Sean's Flight\n",
    "    'CRSArrTime': 2031,\n",
    "    'Distance': 1946,\n",
    "    'OriginSnow_Last2': 0,\n",
    "    'OriginPrcp_Last2': 0,\n",
    "    'OriginSnow': 0,\n",
    "    'OriginPrcp': 0,\n",
    "    'DestSnow_Last2': 0,\n",
    "    'DestPrcp_Last2': 0,\n",
    "    'DestSnow': 0,\n",
    "    'DestPrcp': 0,\n",
    "    'OriginAirport': 'Atlanta, GA: Hartsfield-Jackson Atlanta International',\n",
    "    'DestAirport': 'Los Angeles, CA: Los Angeles International',\n",
    "    'DayOfWeek': 'Wed',\n",
    "    'Airline': 'Delta Air Lines Inc.'\n",
    "}\n",
    "sean_flight_df = pd.DataFrame([sean_flight_data])\n",
    "\n",
    "julia_flight_data = {\n",
    "    'Year': 2023,\n",
    "    'DayofMonth': 17,\n",
    "    'Month': 12,\n",
    "    'CRSDepTime': 932,\n",
    "    'DepDelayMinutes': 0,\n",
    "    'CRSArrTime': 1315,\n",
    "    'Distance': 541.79,\n",
    "    'OriginSnow_Last2': 0,\n",
    "    'OriginPrcp_Last2': 0,\n",
    "    'OriginSnow': 0,\n",
    "    'OriginPrcp': 0,\n",
    "    'DestSnow_Last2': 0,\n",
    "    'DestPrcp_Last2': 1955,\n",
    "    'DestSnow': 0,\n",
    "    'DestPrcp': 1955,\n",
    "    'OriginAirport': 'Atlanta',\n",
    "    'DestAirport': 'Washington, DC: Washington Dulles International',\n",
    "    'DayOfWeek': 'Sun',\n",
    "    'Airline': 'Frontier Airlines Inc.'\n",
    "}\n",
    "julia_flight_df = pd.DataFrame([julia_flight_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then read in the machine learning DataFrame. We will use the same model as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('MLReady.csv')\n",
    "\n",
    "selected_columns = ['Year', 'DayofMonth', 'Month', 'CRSDepTime', 'DepDelayMinutes',\n",
    "                    'CRSArrTime', 'Distance', 'OriginSnow_Last2', 'OriginPrcp_Last2', 'OriginSnow',\n",
    "                    'OriginPrcp', 'DestSnow_Last2', 'DestPrcp_Last2', 'DestSnow', 'DestPrcp',\n",
    "                    'OriginAirport', 'DestAirport', 'DayOfWeek', 'Airline', 'ArrDelayMinutes']\n",
    "\n",
    "df = df[selected_columns]\n",
    "\n",
    "categorical_features = ['OriginAirport', 'DestAirport', 'DayOfWeek', 'Airline']\n",
    "numerical_features = df.drop(columns=['ArrDelayMinutes']).columns.difference(categorical_features)\n",
    "\n",
    "train_data = df[df['Year'] == 2022]\n",
    "\n",
    "X_train = train_data.drop(columns=['ArrDelayMinutes'])\n",
    "y_train = train_data['ArrDelayMinutes']\n",
    "\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                         ('regressor', RandomForestRegressor(n_estimators=10, random_state=42))])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "julia_delay_prediction = model.predict(julia_flight_df)\n",
    "print(f\"Julia's Flight Delay Prediction: {julia_delay_prediction[0]} minutes\")\n",
    "\n",
    "sean_delay_prediction = model.predict(sean_flight_df)\n",
    "print(f\"Sean's Flight Delay Prediction: {sean_delay_prediction[0]} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note to Julia, I was not sure where to put the following in our notebook. Lets discuss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Years for training and testing\n",
    "years_train = [2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
    "mae_values = [6.487981144083558, 6.812233708127388, 5.903338926832098, 6.058833778954674, 6.42770809330232, 6.63172692814846, 4.971198419998488, 5.313820978632428, 6.2656328518457025, 7.222455108552838]\n",
    "r_squared_values = [0.9132239974039758, 0.914890110438901, 0.9279673615797543, 0.9236424608313948, 0.9233149913249296, 0.9363628946806113, 0.916248103806017, 0.9451646019900752, 0.9516300949355766, 0.9558847170121954]\n",
    "\n",
    "# Plot MAE\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(years_train, mae_values, marker='o', linestyle='-', color='b')\n",
    "plt.title('Mean Absolute Error (MAE)')\n",
    "plt.xlabel('Training Year')\n",
    "plt.ylabel('MAE')\n",
    "plt.ylim(0, 10)  # Set y-axis limits\n",
    "\n",
    "# Plot R-squared\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(years_train, r_squared_values, marker='o', linestyle='-', color='r')\n",
    "plt.title('R-squared')\n",
    "plt.xlabel('Training Year')\n",
    "plt.ylabel('R-squared')\n",
    "plt.ylim(0, 1)  # Set y-axis limits\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the error values given to us by the model and plot them. Lastly, below, we graphed the mean delay per airline per year to notice any trends (Note to Julia:) This could be part of the exploratory analysis section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('MLready.csv')\n",
    "\n",
    "grouped_df = df.groupby(['Year', 'Airline'])['ArrDelayMinutes'].mean().reset_index()\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.barplot(x='Year', y='ArrDelayMinutes', hue='Airline', data=grouped_df)\n",
    "\n",
    "plt.title('Average Delays per Airline per Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Average Arrival Delay Minutes per Flight')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
